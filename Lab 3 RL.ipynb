{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 3 RL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iANCzratQWba",
        "colab_type": "code",
        "outputId": "debb2fa7-8a10-41c4-c310-430580ed9769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Laboration 3 Deep reinforcement Learning (Deep Q-learning)\n",
        "# \n",
        "# This laboration is my first experience with the OpenAI gym and the CartPole environment. Gym is basically a Python library that includes several machine learning challenges, \n",
        "# in which an autonomous agent should be learned to fulfill different tasks.One of the simplest and most popular challenges is CartPole. It’s basically a 2D game in which the agent has to control, \n",
        "# i.e. move left or right, a cart to balance a pole standing perpendicularly on the cart. This is a classical reinforcement learning problem. The agents starts by trying random actions as a consequence \n",
        "# to which it gets rewarded (or not). Based on the rewards, it continuously “learns”, which action is good in which specific situation. Doing so, it learns how to master the game without ever being told\n",
        "# how the game even works. CartPole is basically a binary classification problem with four inputs (state variables):\n",
        "#\n",
        "# - position of the cart on the track\n",
        "# - angle of the pole with the vertical\n",
        "# - cart velocity\n",
        "# - rate of change of the angle\n",
        "#\n",
        "# The output is binary, i.e. either 0 or 1, corresponding to “left” or “right”. One challenge is the fact that all four features are continuous values (floating point numbers), which, naively, \n",
        "# implies an infinitely large feature space.\n",
        "#\n",
        "# Having exectuted the program below where the parameter \"EPISODES\" is changed to 1000 you can see that the score varies quite a bit over the period but the variations become less drastic as the agent learns how to become an expert player. \n",
        "# \"Epsilon\" i.e.  is also coming down drastically as it starts with a random value and then stabilizes. I stopped the running for various reasons after 771 episodes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "EPISODES = 1000  # I have changed the parameter from 30 to 1000.\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size): # Initializes the class with \"state_size\" and \"action_size\" parameters\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.95    # Discount rate.\n",
        "        self.epsilon = 1.0  # Exploration rate.\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self): # Builds the neural network model using Keras seqwuential model and returns it. The model has two hidden layers with 24 neurons each. The last output layer has an ouput of \"auction_size\".\n",
        "        model = Sequential()\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu')) # I am using linear activation.\n",
        "        model.add(Dense(24, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse',                                          # Mean Square Error (MSE) loss and the Adam optimizer as characteristics of the neural network.\n",
        "                      optimizer=Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])  # Returns action\n",
        "\n",
        "    def replay(self, batch_size): # A Method that trains the neural network with experiences in the memory.\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = (reward + self.gamma *\n",
        "                          np.amax(self.model.predict(next_state)[0]))\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0) \n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name): # Loads the model weights with the given name.\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name): # Saves the model weights with the given name.\n",
        "        self.model.save_weights(name)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\": # The agent is trained for \"EPISODES\", improving the reward and recalucalting the \"epsilon\".\n",
        "    env = gym.make('CartPole-v1')\n",
        "    state_size = env.observation_space.shape[0]\n",
        "    action_size = env.action_space.n\n",
        "    agent = DQNAgent(state_size, action_size)\n",
        "    done = False\n",
        "    batch_size = 32\n",
        "\n",
        "    for e in range(EPISODES):\n",
        "        state = env.reset()\n",
        "        state = np.reshape(state, [1, state_size])\n",
        "        for time in range(200):\n",
        "            action = agent.act(state) # \"act(state)\" acts based on the previous state and predicts the reward.\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            reward = reward if not done else -10\n",
        "            next_state = np.reshape(next_state, [1, state_size])\n",
        "            agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            if done:\n",
        "                print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
        "                      .format(e, EPISODES, time, agent.epsilon))\n",
        "                break\n",
        "            if len(agent.memory) > batch_size:\n",
        "                agent.replay(batch_size)\n",
        "        \n",
        "        "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0/1000, score: 13, e: 1.0\n",
            "episode: 1/1000, score: 41, e: 0.89\n",
            "episode: 2/1000, score: 29, e: 0.77\n",
            "episode: 3/1000, score: 19, e: 0.7\n",
            "episode: 4/1000, score: 10, e: 0.67\n",
            "episode: 5/1000, score: 15, e: 0.62\n",
            "episode: 6/1000, score: 14, e: 0.58\n",
            "episode: 7/1000, score: 20, e: 0.52\n",
            "episode: 8/1000, score: 12, e: 0.49\n",
            "episode: 9/1000, score: 19, e: 0.45\n",
            "episode: 10/1000, score: 25, e: 0.39\n",
            "episode: 11/1000, score: 11, e: 0.37\n",
            "episode: 12/1000, score: 15, e: 0.35\n",
            "episode: 13/1000, score: 24, e: 0.31\n",
            "episode: 14/1000, score: 21, e: 0.28\n",
            "episode: 15/1000, score: 32, e: 0.23\n",
            "episode: 16/1000, score: 46, e: 0.19\n",
            "episode: 17/1000, score: 49, e: 0.15\n",
            "episode: 18/1000, score: 157, e: 0.066\n",
            "episode: 19/1000, score: 106, e: 0.039\n",
            "episode: 20/1000, score: 91, e: 0.025\n",
            "episode: 22/1000, score: 193, e: 0.01\n",
            "episode: 23/1000, score: 187, e: 0.01\n",
            "episode: 30/1000, score: 108, e: 0.01\n",
            "episode: 31/1000, score: 9, e: 0.01\n",
            "episode: 32/1000, score: 8, e: 0.01\n",
            "episode: 35/1000, score: 153, e: 0.01\n",
            "episode: 37/1000, score: 129, e: 0.01\n",
            "episode: 41/1000, score: 195, e: 0.01\n",
            "episode: 45/1000, score: 184, e: 0.01\n",
            "episode: 46/1000, score: 8, e: 0.01\n",
            "episode: 47/1000, score: 9, e: 0.01\n",
            "episode: 48/1000, score: 9, e: 0.01\n",
            "episode: 49/1000, score: 22, e: 0.01\n",
            "episode: 50/1000, score: 17, e: 0.01\n",
            "episode: 53/1000, score: 175, e: 0.01\n",
            "episode: 56/1000, score: 112, e: 0.01\n",
            "episode: 57/1000, score: 173, e: 0.01\n",
            "episode: 58/1000, score: 175, e: 0.01\n",
            "episode: 61/1000, score: 98, e: 0.01\n",
            "episode: 63/1000, score: 139, e: 0.01\n",
            "episode: 68/1000, score: 15, e: 0.01\n",
            "episode: 71/1000, score: 62, e: 0.01\n",
            "episode: 72/1000, score: 21, e: 0.01\n",
            "episode: 74/1000, score: 46, e: 0.01\n",
            "episode: 75/1000, score: 149, e: 0.01\n",
            "episode: 83/1000, score: 133, e: 0.01\n",
            "episode: 89/1000, score: 184, e: 0.01\n",
            "episode: 90/1000, score: 31, e: 0.01\n",
            "episode: 91/1000, score: 90, e: 0.01\n",
            "episode: 92/1000, score: 24, e: 0.01\n",
            "episode: 93/1000, score: 178, e: 0.01\n",
            "episode: 94/1000, score: 43, e: 0.01\n",
            "episode: 95/1000, score: 186, e: 0.01\n",
            "episode: 96/1000, score: 143, e: 0.01\n",
            "episode: 98/1000, score: 182, e: 0.01\n",
            "episode: 99/1000, score: 178, e: 0.01\n",
            "episode: 100/1000, score: 173, e: 0.01\n",
            "episode: 102/1000, score: 166, e: 0.01\n",
            "episode: 103/1000, score: 181, e: 0.01\n",
            "episode: 105/1000, score: 186, e: 0.01\n",
            "episode: 106/1000, score: 53, e: 0.01\n",
            "episode: 108/1000, score: 93, e: 0.01\n",
            "episode: 109/1000, score: 104, e: 0.01\n",
            "episode: 110/1000, score: 138, e: 0.01\n",
            "episode: 111/1000, score: 173, e: 0.01\n",
            "episode: 112/1000, score: 181, e: 0.01\n",
            "episode: 113/1000, score: 179, e: 0.01\n",
            "episode: 120/1000, score: 105, e: 0.01\n",
            "episode: 121/1000, score: 8, e: 0.01\n",
            "episode: 122/1000, score: 141, e: 0.01\n",
            "episode: 123/1000, score: 95, e: 0.01\n",
            "episode: 124/1000, score: 62, e: 0.01\n",
            "episode: 125/1000, score: 32, e: 0.01\n",
            "episode: 126/1000, score: 9, e: 0.01\n",
            "episode: 127/1000, score: 9, e: 0.01\n",
            "episode: 128/1000, score: 8, e: 0.01\n",
            "episode: 129/1000, score: 9, e: 0.01\n",
            "episode: 130/1000, score: 8, e: 0.01\n",
            "episode: 131/1000, score: 9, e: 0.01\n",
            "episode: 132/1000, score: 8, e: 0.01\n",
            "episode: 133/1000, score: 10, e: 0.01\n",
            "episode: 134/1000, score: 7, e: 0.01\n",
            "episode: 135/1000, score: 9, e: 0.01\n",
            "episode: 136/1000, score: 9, e: 0.01\n",
            "episode: 137/1000, score: 8, e: 0.01\n",
            "episode: 138/1000, score: 8, e: 0.01\n",
            "episode: 139/1000, score: 169, e: 0.01\n",
            "episode: 140/1000, score: 25, e: 0.01\n",
            "episode: 141/1000, score: 24, e: 0.01\n",
            "episode: 142/1000, score: 21, e: 0.01\n",
            "episode: 143/1000, score: 50, e: 0.01\n",
            "episode: 144/1000, score: 36, e: 0.01\n",
            "episode: 145/1000, score: 102, e: 0.01\n",
            "episode: 153/1000, score: 188, e: 0.01\n",
            "episode: 156/1000, score: 31, e: 0.01\n",
            "episode: 158/1000, score: 99, e: 0.01\n",
            "episode: 159/1000, score: 83, e: 0.01\n",
            "episode: 160/1000, score: 133, e: 0.01\n",
            "episode: 161/1000, score: 42, e: 0.01\n",
            "episode: 167/1000, score: 139, e: 0.01\n",
            "episode: 168/1000, score: 152, e: 0.01\n",
            "episode: 169/1000, score: 141, e: 0.01\n",
            "episode: 170/1000, score: 62, e: 0.01\n",
            "episode: 171/1000, score: 179, e: 0.01\n",
            "episode: 172/1000, score: 151, e: 0.01\n",
            "episode: 173/1000, score: 130, e: 0.01\n",
            "episode: 174/1000, score: 84, e: 0.01\n",
            "episode: 175/1000, score: 197, e: 0.01\n",
            "episode: 177/1000, score: 63, e: 0.01\n",
            "episode: 179/1000, score: 157, e: 0.01\n",
            "episode: 180/1000, score: 191, e: 0.01\n",
            "episode: 183/1000, score: 25, e: 0.01\n",
            "episode: 184/1000, score: 62, e: 0.01\n",
            "episode: 185/1000, score: 31, e: 0.01\n",
            "episode: 186/1000, score: 10, e: 0.01\n",
            "episode: 188/1000, score: 146, e: 0.01\n",
            "episode: 192/1000, score: 135, e: 0.01\n",
            "episode: 193/1000, score: 135, e: 0.01\n",
            "episode: 194/1000, score: 146, e: 0.01\n",
            "episode: 196/1000, score: 127, e: 0.01\n",
            "episode: 200/1000, score: 192, e: 0.01\n",
            "episode: 205/1000, score: 85, e: 0.01\n",
            "episode: 206/1000, score: 11, e: 0.01\n",
            "episode: 207/1000, score: 18, e: 0.01\n",
            "episode: 210/1000, score: 170, e: 0.01\n",
            "episode: 211/1000, score: 187, e: 0.01\n",
            "episode: 212/1000, score: 171, e: 0.01\n",
            "episode: 213/1000, score: 172, e: 0.01\n",
            "episode: 219/1000, score: 125, e: 0.01\n",
            "episode: 222/1000, score: 127, e: 0.01\n",
            "episode: 223/1000, score: 132, e: 0.01\n",
            "episode: 224/1000, score: 113, e: 0.01\n",
            "episode: 225/1000, score: 114, e: 0.01\n",
            "episode: 226/1000, score: 77, e: 0.01\n",
            "episode: 228/1000, score: 161, e: 0.01\n",
            "episode: 229/1000, score: 164, e: 0.01\n",
            "episode: 231/1000, score: 10, e: 0.01\n",
            "episode: 234/1000, score: 161, e: 0.01\n",
            "episode: 240/1000, score: 194, e: 0.01\n",
            "episode: 242/1000, score: 102, e: 0.01\n",
            "episode: 244/1000, score: 74, e: 0.01\n",
            "episode: 247/1000, score: 186, e: 0.01\n",
            "episode: 249/1000, score: 158, e: 0.01\n",
            "episode: 254/1000, score: 170, e: 0.01\n",
            "episode: 255/1000, score: 180, e: 0.01\n",
            "episode: 256/1000, score: 76, e: 0.01\n",
            "episode: 257/1000, score: 72, e: 0.01\n",
            "episode: 258/1000, score: 10, e: 0.01\n",
            "episode: 267/1000, score: 192, e: 0.01\n",
            "episode: 270/1000, score: 68, e: 0.01\n",
            "episode: 271/1000, score: 49, e: 0.01\n",
            "episode: 272/1000, score: 199, e: 0.01\n",
            "episode: 273/1000, score: 26, e: 0.01\n",
            "episode: 274/1000, score: 9, e: 0.01\n",
            "episode: 275/1000, score: 12, e: 0.01\n",
            "episode: 276/1000, score: 12, e: 0.01\n",
            "episode: 277/1000, score: 14, e: 0.01\n",
            "episode: 278/1000, score: 11, e: 0.01\n",
            "episode: 279/1000, score: 115, e: 0.01\n",
            "episode: 280/1000, score: 166, e: 0.01\n",
            "episode: 281/1000, score: 166, e: 0.01\n",
            "episode: 282/1000, score: 161, e: 0.01\n",
            "episode: 286/1000, score: 140, e: 0.01\n",
            "episode: 289/1000, score: 150, e: 0.01\n",
            "episode: 292/1000, score: 148, e: 0.01\n",
            "episode: 293/1000, score: 126, e: 0.01\n",
            "episode: 294/1000, score: 128, e: 0.01\n",
            "episode: 306/1000, score: 121, e: 0.01\n",
            "episode: 308/1000, score: 156, e: 0.01\n",
            "episode: 311/1000, score: 159, e: 0.01\n",
            "episode: 313/1000, score: 121, e: 0.01\n",
            "episode: 318/1000, score: 69, e: 0.01\n",
            "episode: 319/1000, score: 43, e: 0.01\n",
            "episode: 320/1000, score: 10, e: 0.01\n",
            "episode: 321/1000, score: 9, e: 0.01\n",
            "episode: 322/1000, score: 17, e: 0.01\n",
            "episode: 323/1000, score: 115, e: 0.01\n",
            "episode: 324/1000, score: 105, e: 0.01\n",
            "episode: 326/1000, score: 100, e: 0.01\n",
            "episode: 327/1000, score: 177, e: 0.01\n",
            "episode: 328/1000, score: 177, e: 0.01\n",
            "episode: 329/1000, score: 133, e: 0.01\n",
            "episode: 330/1000, score: 116, e: 0.01\n",
            "episode: 331/1000, score: 105, e: 0.01\n",
            "episode: 332/1000, score: 167, e: 0.01\n",
            "episode: 333/1000, score: 152, e: 0.01\n",
            "episode: 334/1000, score: 117, e: 0.01\n",
            "episode: 335/1000, score: 133, e: 0.01\n",
            "episode: 336/1000, score: 161, e: 0.01\n",
            "episode: 337/1000, score: 127, e: 0.01\n",
            "episode: 341/1000, score: 74, e: 0.01\n",
            "episode: 342/1000, score: 9, e: 0.01\n",
            "episode: 344/1000, score: 182, e: 0.01\n",
            "episode: 345/1000, score: 197, e: 0.01\n",
            "episode: 348/1000, score: 102, e: 0.01\n",
            "episode: 353/1000, score: 168, e: 0.01\n",
            "episode: 355/1000, score: 186, e: 0.01\n",
            "episode: 358/1000, score: 153, e: 0.01\n",
            "episode: 359/1000, score: 9, e: 0.01\n",
            "episode: 360/1000, score: 9, e: 0.01\n",
            "episode: 361/1000, score: 8, e: 0.01\n",
            "episode: 362/1000, score: 8, e: 0.01\n",
            "episode: 363/1000, score: 9, e: 0.01\n",
            "episode: 364/1000, score: 8, e: 0.01\n",
            "episode: 365/1000, score: 7, e: 0.01\n",
            "episode: 366/1000, score: 8, e: 0.01\n",
            "episode: 367/1000, score: 7, e: 0.01\n",
            "episode: 368/1000, score: 10, e: 0.01\n",
            "episode: 369/1000, score: 9, e: 0.01\n",
            "episode: 370/1000, score: 7, e: 0.01\n",
            "episode: 371/1000, score: 9, e: 0.01\n",
            "episode: 372/1000, score: 9, e: 0.01\n",
            "episode: 373/1000, score: 8, e: 0.01\n",
            "episode: 374/1000, score: 9, e: 0.01\n",
            "episode: 375/1000, score: 9, e: 0.01\n",
            "episode: 376/1000, score: 8, e: 0.01\n",
            "episode: 377/1000, score: 9, e: 0.01\n",
            "episode: 378/1000, score: 9, e: 0.01\n",
            "episode: 379/1000, score: 8, e: 0.01\n",
            "episode: 380/1000, score: 23, e: 0.01\n",
            "episode: 381/1000, score: 9, e: 0.01\n",
            "episode: 382/1000, score: 14, e: 0.01\n",
            "episode: 383/1000, score: 16, e: 0.01\n",
            "episode: 384/1000, score: 57, e: 0.01\n",
            "episode: 385/1000, score: 41, e: 0.01\n",
            "episode: 386/1000, score: 69, e: 0.01\n",
            "episode: 387/1000, score: 131, e: 0.01\n",
            "episode: 389/1000, score: 117, e: 0.01\n",
            "episode: 391/1000, score: 129, e: 0.01\n",
            "episode: 397/1000, score: 189, e: 0.01\n",
            "episode: 399/1000, score: 142, e: 0.01\n",
            "episode: 403/1000, score: 169, e: 0.01\n",
            "episode: 404/1000, score: 31, e: 0.01\n",
            "episode: 405/1000, score: 59, e: 0.01\n",
            "episode: 406/1000, score: 118, e: 0.01\n",
            "episode: 407/1000, score: 21, e: 0.01\n",
            "episode: 408/1000, score: 108, e: 0.01\n",
            "episode: 409/1000, score: 122, e: 0.01\n",
            "episode: 410/1000, score: 32, e: 0.01\n",
            "episode: 411/1000, score: 127, e: 0.01\n",
            "episode: 412/1000, score: 111, e: 0.01\n",
            "episode: 413/1000, score: 109, e: 0.01\n",
            "episode: 414/1000, score: 133, e: 0.01\n",
            "episode: 415/1000, score: 162, e: 0.01\n",
            "episode: 416/1000, score: 117, e: 0.01\n",
            "episode: 417/1000, score: 11, e: 0.01\n",
            "episode: 418/1000, score: 128, e: 0.01\n",
            "episode: 419/1000, score: 147, e: 0.01\n",
            "episode: 422/1000, score: 161, e: 0.01\n",
            "episode: 424/1000, score: 175, e: 0.01\n",
            "episode: 425/1000, score: 123, e: 0.01\n",
            "episode: 426/1000, score: 188, e: 0.01\n",
            "episode: 427/1000, score: 12, e: 0.01\n",
            "episode: 428/1000, score: 15, e: 0.01\n",
            "episode: 429/1000, score: 163, e: 0.01\n",
            "episode: 438/1000, score: 27, e: 0.01\n",
            "episode: 439/1000, score: 101, e: 0.01\n",
            "episode: 440/1000, score: 131, e: 0.01\n",
            "episode: 441/1000, score: 57, e: 0.01\n",
            "episode: 442/1000, score: 26, e: 0.01\n",
            "episode: 443/1000, score: 140, e: 0.01\n",
            "episode: 444/1000, score: 8, e: 0.01\n",
            "episode: 445/1000, score: 7, e: 0.01\n",
            "episode: 446/1000, score: 8, e: 0.01\n",
            "episode: 447/1000, score: 9, e: 0.01\n",
            "episode: 448/1000, score: 9, e: 0.01\n",
            "episode: 449/1000, score: 10, e: 0.01\n",
            "episode: 450/1000, score: 9, e: 0.01\n",
            "episode: 451/1000, score: 8, e: 0.01\n",
            "episode: 452/1000, score: 8, e: 0.01\n",
            "episode: 453/1000, score: 8, e: 0.01\n",
            "episode: 454/1000, score: 9, e: 0.01\n",
            "episode: 455/1000, score: 7, e: 0.01\n",
            "episode: 456/1000, score: 8, e: 0.01\n",
            "episode: 457/1000, score: 9, e: 0.01\n",
            "episode: 458/1000, score: 8, e: 0.01\n",
            "episode: 459/1000, score: 9, e: 0.01\n",
            "episode: 460/1000, score: 7, e: 0.01\n",
            "episode: 461/1000, score: 7, e: 0.01\n",
            "episode: 462/1000, score: 11, e: 0.01\n",
            "episode: 463/1000, score: 16, e: 0.01\n",
            "episode: 464/1000, score: 122, e: 0.01\n",
            "episode: 465/1000, score: 140, e: 0.01\n",
            "episode: 466/1000, score: 106, e: 0.01\n",
            "episode: 467/1000, score: 116, e: 0.01\n",
            "episode: 468/1000, score: 118, e: 0.01\n",
            "episode: 469/1000, score: 131, e: 0.01\n",
            "episode: 470/1000, score: 149, e: 0.01\n",
            "episode: 471/1000, score: 162, e: 0.01\n",
            "episode: 473/1000, score: 159, e: 0.01\n",
            "episode: 475/1000, score: 111, e: 0.01\n",
            "episode: 476/1000, score: 14, e: 0.01\n",
            "episode: 477/1000, score: 92, e: 0.01\n",
            "episode: 482/1000, score: 158, e: 0.01\n",
            "episode: 483/1000, score: 133, e: 0.01\n",
            "episode: 484/1000, score: 117, e: 0.01\n",
            "episode: 486/1000, score: 82, e: 0.01\n",
            "episode: 487/1000, score: 175, e: 0.01\n",
            "episode: 489/1000, score: 165, e: 0.01\n",
            "episode: 490/1000, score: 166, e: 0.01\n",
            "episode: 492/1000, score: 160, e: 0.01\n",
            "episode: 496/1000, score: 175, e: 0.01\n",
            "episode: 497/1000, score: 37, e: 0.01\n",
            "episode: 498/1000, score: 117, e: 0.01\n",
            "episode: 503/1000, score: 141, e: 0.01\n",
            "episode: 504/1000, score: 112, e: 0.01\n",
            "episode: 505/1000, score: 126, e: 0.01\n",
            "episode: 506/1000, score: 47, e: 0.01\n",
            "episode: 508/1000, score: 125, e: 0.01\n",
            "episode: 511/1000, score: 43, e: 0.01\n",
            "episode: 512/1000, score: 144, e: 0.01\n",
            "episode: 513/1000, score: 171, e: 0.01\n",
            "episode: 516/1000, score: 101, e: 0.01\n",
            "episode: 518/1000, score: 190, e: 0.01\n",
            "episode: 522/1000, score: 145, e: 0.01\n",
            "episode: 526/1000, score: 156, e: 0.01\n",
            "episode: 530/1000, score: 159, e: 0.01\n",
            "episode: 535/1000, score: 44, e: 0.01\n",
            "episode: 536/1000, score: 116, e: 0.01\n",
            "episode: 537/1000, score: 54, e: 0.01\n",
            "episode: 538/1000, score: 115, e: 0.01\n",
            "episode: 539/1000, score: 119, e: 0.01\n",
            "episode: 543/1000, score: 185, e: 0.01\n",
            "episode: 544/1000, score: 121, e: 0.01\n",
            "episode: 546/1000, score: 171, e: 0.01\n",
            "episode: 547/1000, score: 148, e: 0.01\n",
            "episode: 548/1000, score: 123, e: 0.01\n",
            "episode: 549/1000, score: 188, e: 0.01\n",
            "episode: 550/1000, score: 74, e: 0.01\n",
            "episode: 551/1000, score: 8, e: 0.01\n",
            "episode: 552/1000, score: 9, e: 0.01\n",
            "episode: 553/1000, score: 34, e: 0.01\n",
            "episode: 554/1000, score: 35, e: 0.01\n",
            "episode: 555/1000, score: 26, e: 0.01\n",
            "episode: 556/1000, score: 23, e: 0.01\n",
            "episode: 557/1000, score: 104, e: 0.01\n",
            "episode: 558/1000, score: 74, e: 0.01\n",
            "episode: 559/1000, score: 119, e: 0.01\n",
            "episode: 560/1000, score: 21, e: 0.01\n",
            "episode: 561/1000, score: 85, e: 0.01\n",
            "episode: 562/1000, score: 71, e: 0.01\n",
            "episode: 563/1000, score: 94, e: 0.01\n",
            "episode: 569/1000, score: 169, e: 0.01\n",
            "episode: 572/1000, score: 139, e: 0.01\n",
            "episode: 573/1000, score: 7, e: 0.01\n",
            "episode: 574/1000, score: 9, e: 0.01\n",
            "episode: 576/1000, score: 18, e: 0.01\n",
            "episode: 577/1000, score: 11, e: 0.01\n",
            "episode: 583/1000, score: 155, e: 0.01\n",
            "episode: 586/1000, score: 169, e: 0.01\n",
            "episode: 588/1000, score: 9, e: 0.01\n",
            "episode: 589/1000, score: 9, e: 0.01\n",
            "episode: 590/1000, score: 10, e: 0.01\n",
            "episode: 591/1000, score: 7, e: 0.01\n",
            "episode: 592/1000, score: 9, e: 0.01\n",
            "episode: 593/1000, score: 9, e: 0.01\n",
            "episode: 594/1000, score: 9, e: 0.01\n",
            "episode: 595/1000, score: 9, e: 0.01\n",
            "episode: 596/1000, score: 9, e: 0.01\n",
            "episode: 597/1000, score: 8, e: 0.01\n",
            "episode: 598/1000, score: 8, e: 0.01\n",
            "episode: 599/1000, score: 7, e: 0.01\n",
            "episode: 600/1000, score: 8, e: 0.01\n",
            "episode: 601/1000, score: 8, e: 0.01\n",
            "episode: 602/1000, score: 9, e: 0.01\n",
            "episode: 603/1000, score: 9, e: 0.01\n",
            "episode: 604/1000, score: 9, e: 0.01\n",
            "episode: 605/1000, score: 10, e: 0.01\n",
            "episode: 606/1000, score: 10, e: 0.01\n",
            "episode: 607/1000, score: 12, e: 0.01\n",
            "episode: 608/1000, score: 63, e: 0.01\n",
            "episode: 609/1000, score: 21, e: 0.01\n",
            "episode: 610/1000, score: 23, e: 0.01\n",
            "episode: 611/1000, score: 19, e: 0.01\n",
            "episode: 612/1000, score: 30, e: 0.01\n",
            "episode: 613/1000, score: 26, e: 0.01\n",
            "episode: 614/1000, score: 36, e: 0.01\n",
            "episode: 616/1000, score: 171, e: 0.01\n",
            "episode: 617/1000, score: 164, e: 0.01\n",
            "episode: 619/1000, score: 176, e: 0.01\n",
            "episode: 620/1000, score: 160, e: 0.01\n",
            "episode: 621/1000, score: 155, e: 0.01\n",
            "episode: 622/1000, score: 117, e: 0.01\n",
            "episode: 624/1000, score: 147, e: 0.01\n",
            "episode: 625/1000, score: 120, e: 0.01\n",
            "episode: 626/1000, score: 144, e: 0.01\n",
            "episode: 627/1000, score: 17, e: 0.01\n",
            "episode: 628/1000, score: 151, e: 0.01\n",
            "episode: 629/1000, score: 162, e: 0.01\n",
            "episode: 630/1000, score: 119, e: 0.01\n",
            "episode: 631/1000, score: 14, e: 0.01\n",
            "episode: 632/1000, score: 39, e: 0.01\n",
            "episode: 633/1000, score: 101, e: 0.01\n",
            "episode: 634/1000, score: 77, e: 0.01\n",
            "episode: 635/1000, score: 18, e: 0.01\n",
            "episode: 636/1000, score: 10, e: 0.01\n",
            "episode: 637/1000, score: 41, e: 0.01\n",
            "episode: 638/1000, score: 140, e: 0.01\n",
            "episode: 639/1000, score: 28, e: 0.01\n",
            "episode: 640/1000, score: 146, e: 0.01\n",
            "episode: 641/1000, score: 136, e: 0.01\n",
            "episode: 642/1000, score: 167, e: 0.01\n",
            "episode: 643/1000, score: 173, e: 0.01\n",
            "episode: 644/1000, score: 179, e: 0.01\n",
            "episode: 645/1000, score: 181, e: 0.01\n",
            "episode: 646/1000, score: 149, e: 0.01\n",
            "episode: 647/1000, score: 173, e: 0.01\n",
            "episode: 648/1000, score: 156, e: 0.01\n",
            "episode: 649/1000, score: 180, e: 0.01\n",
            "episode: 650/1000, score: 178, e: 0.01\n",
            "episode: 651/1000, score: 172, e: 0.01\n",
            "episode: 652/1000, score: 141, e: 0.01\n",
            "episode: 653/1000, score: 52, e: 0.01\n",
            "episode: 654/1000, score: 10, e: 0.01\n",
            "episode: 655/1000, score: 135, e: 0.01\n",
            "episode: 656/1000, score: 143, e: 0.01\n",
            "episode: 658/1000, score: 130, e: 0.01\n",
            "episode: 659/1000, score: 166, e: 0.01\n",
            "episode: 660/1000, score: 103, e: 0.01\n",
            "episode: 664/1000, score: 187, e: 0.01\n",
            "episode: 668/1000, score: 193, e: 0.01\n",
            "episode: 669/1000, score: 137, e: 0.01\n",
            "episode: 670/1000, score: 9, e: 0.01\n",
            "episode: 671/1000, score: 7, e: 0.01\n",
            "episode: 672/1000, score: 8, e: 0.01\n",
            "episode: 673/1000, score: 12, e: 0.01\n",
            "episode: 674/1000, score: 93, e: 0.01\n",
            "episode: 677/1000, score: 90, e: 0.01\n",
            "episode: 678/1000, score: 25, e: 0.01\n",
            "episode: 679/1000, score: 7, e: 0.01\n",
            "episode: 687/1000, score: 80, e: 0.01\n",
            "episode: 690/1000, score: 183, e: 0.01\n",
            "episode: 691/1000, score: 7, e: 0.01\n",
            "episode: 692/1000, score: 10, e: 0.01\n",
            "episode: 703/1000, score: 157, e: 0.01\n",
            "episode: 704/1000, score: 117, e: 0.01\n",
            "episode: 705/1000, score: 8, e: 0.01\n",
            "episode: 706/1000, score: 7, e: 0.01\n",
            "episode: 707/1000, score: 20, e: 0.01\n",
            "episode: 708/1000, score: 8, e: 0.01\n",
            "episode: 719/1000, score: 115, e: 0.01\n",
            "episode: 720/1000, score: 11, e: 0.01\n",
            "episode: 721/1000, score: 194, e: 0.01\n",
            "episode: 723/1000, score: 180, e: 0.01\n",
            "episode: 724/1000, score: 54, e: 0.01\n",
            "episode: 728/1000, score: 116, e: 0.01\n",
            "episode: 729/1000, score: 199, e: 0.01\n",
            "episode: 730/1000, score: 190, e: 0.01\n",
            "episode: 731/1000, score: 165, e: 0.01\n",
            "episode: 732/1000, score: 158, e: 0.01\n",
            "episode: 733/1000, score: 132, e: 0.01\n",
            "episode: 734/1000, score: 146, e: 0.01\n",
            "episode: 735/1000, score: 25, e: 0.01\n",
            "episode: 736/1000, score: 11, e: 0.01\n",
            "episode: 737/1000, score: 159, e: 0.01\n",
            "episode: 738/1000, score: 146, e: 0.01\n",
            "episode: 739/1000, score: 8, e: 0.01\n",
            "episode: 740/1000, score: 9, e: 0.01\n",
            "episode: 741/1000, score: 9, e: 0.01\n",
            "episode: 742/1000, score: 138, e: 0.01\n",
            "episode: 743/1000, score: 184, e: 0.01\n",
            "episode: 744/1000, score: 149, e: 0.01\n",
            "episode: 745/1000, score: 77, e: 0.01\n",
            "episode: 746/1000, score: 42, e: 0.01\n",
            "episode: 747/1000, score: 175, e: 0.01\n",
            "episode: 748/1000, score: 170, e: 0.01\n",
            "episode: 749/1000, score: 170, e: 0.01\n",
            "episode: 750/1000, score: 121, e: 0.01\n",
            "episode: 755/1000, score: 194, e: 0.01\n",
            "episode: 756/1000, score: 148, e: 0.01\n",
            "episode: 757/1000, score: 128, e: 0.01\n",
            "episode: 758/1000, score: 77, e: 0.01\n",
            "episode: 763/1000, score: 196, e: 0.01\n",
            "episode: 764/1000, score: 178, e: 0.01\n",
            "episode: 766/1000, score: 67, e: 0.01\n",
            "episode: 767/1000, score: 151, e: 0.01\n",
            "episode: 768/1000, score: 121, e: 0.01\n",
            "episode: 769/1000, score: 121, e: 0.01\n",
            "episode: 770/1000, score: 9, e: 0.01\n",
            "episode: 771/1000, score: 131, e: 0.01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1e0f56aff56d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1e0f56aff56d>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 target = (reward + self.gamma *\n\u001b[1;32m     51\u001b[0m                           np.amax(self.model.predict(next_state)[0]))\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRWTH-ahcIrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}